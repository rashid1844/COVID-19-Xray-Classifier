{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "import datetime\n",
    "from keras.models import load_model\n",
    "import csv\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dropout\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import metrics\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transfer learning \n",
    "1- train top layer with 128x128 (2 epochs)\n",
    "\n",
    "2- train the whole network with 128x128 (10 epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Parameters\n",
    "batch_size = 32 \n",
    "top_epochs = 2\n",
    "\n",
    "output_size = 3\n",
    "classes = ['normal', 'pneumonia', 'COVID-19']\n",
    "\n",
    "target_size= (128, 128)\n",
    "\n",
    "train_size = 37974\n",
    "test_size = 4235\n",
    "train_step = np.ceil(train_size/batch_size) \n",
    "test_step = 2  \n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashid\\Anaconda3\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "\n",
    "# add a top layer\n",
    "x = base_model.output\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(output_size, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37974 images belonging to 3 classes.\n",
      "Found 4235 images belonging to 3 classes.\n",
      "Epoch 1/2\n",
      "1187/1187 [==============================] - 631s 531ms/step - loss: 0.4807 - acc: 0.8195 - val_loss: 1.1370 - val_acc: 0.6094\n",
      "Epoch 2/2\n",
      "1187/1187 [==============================] - 613s 516ms/step - loss: 0.3911 - acc: 0.8607 - val_loss: 1.2690 - val_acc: 0.6094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x19efa544e48>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train top layers only (128x128)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "model.fit_generator(datagen.flow_from_directory('data/train', classes=classes, class_mode='categorical',target_size=target_size), \n",
    "            steps_per_epoch=train_step, epochs=top_epochs, verbose=verbose, \n",
    "            validation_data=test_datagen.flow_from_directory('data/test', classes=classes, class_mode='categorical',target_size=target_size),\n",
    "            validation_steps=test_step)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37974 images belonging to 3 classes.\n",
      "Found 4235 images belonging to 3 classes.\n",
      "Epoch 1/10\n",
      "1187/1187 [==============================] - 689s 581ms/step - loss: 0.5877 - acc: 0.7922 - val_loss: 0.6757 - val_acc: 0.6719\n",
      "Epoch 2/10\n",
      "1187/1187 [==============================] - 687s 579ms/step - loss: 0.4055 - acc: 0.8563 - val_loss: 1.1105 - val_acc: 0.6875\n",
      "Epoch 3/10\n",
      "1187/1187 [==============================] - 691s 582ms/step - loss: 0.3743 - acc: 0.8718 - val_loss: 0.3859 - val_acc: 0.9062\n",
      "Epoch 4/10\n",
      "1187/1187 [==============================] - 662s 558ms/step - loss: 0.4130 - acc: 0.8514 - val_loss: 0.3563 - val_acc: 0.8906\n",
      "Epoch 5/10\n",
      "1187/1187 [==============================] - 648s 546ms/step - loss: 0.3060 - acc: 0.8883 - val_loss: 0.6474 - val_acc: 0.7031\n",
      "Epoch 6/10\n",
      "1187/1187 [==============================] - 645s 543ms/step - loss: 0.3337 - acc: 0.8766 - val_loss: 0.7510 - val_acc: 0.6406\n",
      "Epoch 7/10\n",
      "1187/1187 [==============================] - 648s 546ms/step - loss: 0.3499 - acc: 0.8783 - val_loss: 0.7404 - val_acc: 0.7188\n",
      "Epoch 8/10\n",
      "1187/1187 [==============================] - 679s 572ms/step - loss: 0.2842 - acc: 0.8907 - val_loss: 1.0104 - val_acc: 0.4531\n",
      "Epoch 9/10\n",
      "1187/1187 [==============================] - 673s 567ms/step - loss: 0.2594 - acc: 0.9002 - val_loss: 0.2635 - val_acc: 0.8906\n",
      "Epoch 10/10\n",
      "1187/1187 [==============================] - 654s 551ms/step - loss: 0.2372 - acc: 0.9131 - val_loss: 0.4444 - val_acc: 0.8594\n"
     ]
    }
   ],
   "source": [
    "#Train with 128x128 full network\n",
    "epochs= 10\n",
    "N=0\n",
    "    \n",
    "for layer in model.layers[:N]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[N:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "\n",
    "model.compile('adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "model.fit_generator(datagen.flow_from_directory('data/train', classes=classes, class_mode='categorical',target_size=target_size), \n",
    "                    steps_per_epoch=train_step, epochs=epochs, verbose=verbose, \n",
    "                    validation_data=test_datagen.flow_from_directory('data/test', classes=classes, class_mode='categorical',target_size=target_size),\n",
    "                    validation_steps=test_step, use_multiprocessing=False)\n",
    "\n",
    "model.save('models/ResNet128.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
